{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('penguins_lter.csv')  # Ensure the path to your dataset is correct\n",
        "\n",
        "# Clean the dataset (dropping rows with missing values)\n",
        "cleaned_data = data.dropna(subset=['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)'])\n",
        "\n",
        "# Convert numeric columns to categorical bins\n",
        "cleaned_data.loc[:, 'Culmen Length (mm)'] = pd.cut(cleaned_data['Culmen Length (mm)'], bins=3, labels=[\"short\", \"medium\", \"long\"])\n",
        "cleaned_data.loc[:, 'Culmen Depth (mm)'] = pd.cut(cleaned_data['Culmen Depth (mm)'], bins=3, labels=[\"shallow\", \"medium\", \"deep\"])\n",
        "cleaned_data.loc[:, 'Flipper Length (mm)'] = pd.cut(cleaned_data['Flipper Length (mm)'], bins=3, labels=[\"short\", \"medium\", \"long\"])\n",
        "cleaned_data.loc[:, 'Body Mass (g)'] = pd.cut(cleaned_data['Body Mass (g)'], bins=3, labels=[\"light\", \"medium\", \"heavy\"])\n",
        "\n",
        "# One-hot encode the categorical data\n",
        "one_hot_data = pd.get_dummies(cleaned_data[['Species', 'Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']])\n",
        "\n",
        "# Apply the Apriori algorithm\n",
        "frequent_itemsets = apriori(one_hot_data, min_support=0.1, use_colnames=True)\n",
        "\n",
        "# Generate the association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.6)\n",
        "\n",
        "# Filter rules with support > 0.3 and confidence > 0.8\n",
        "filtered_rules = rules[(rules['support'] > 0.3) & (rules['confidence'] > 0.8)]\n",
        "\n",
        "# Select only relevant columns: antecedents, support, and confidence\n",
        "cleaned_output = filtered_rules[['antecedents', 'support', 'confidence']]\n",
        "\n",
        "# Display the cleaned output without row indices\n",
        "print(cleaned_output.to_string(index=False))\n",
        "\n",
        "# Optionally save the cleaned output to a CSV file\n",
        "# cleaned_output.to_csv('cleaned_association_rules.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4CdJILp7pVn",
        "outputId": "5eaf12a7-1186-4840-c911-65d20e626ffb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  antecedents  support  confidence\n",
            "                   (Culmen Length (mm)_short) 0.365497    0.984252\n",
            "(Species_Adelie Penguin (Pygoscelis adeliae)) 0.365497    0.827815\n",
            "  (Species_Gentoo penguin (Pygoscelis papua)) 0.304094    0.845528\n"
          ]
        }
      ]
    }
  ]
}